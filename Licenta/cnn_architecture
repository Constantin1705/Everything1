digraph {
	Input [label="Input Layer: 32x32x3"]
	Conv1 [label="Conv2D: 32x32x32
kernel=3x3, padding=1"]
	ReLU1 [label="ReLU Activation"]
	Conv2 [label="Conv2D: 32x32x64
kernel=3x3, padding=1"]
	ReLU2 [label="ReLU Activation"]
	Conv3 [label="Conv2D: 32x32x128
kernel=3x3, padding=1"]
	ReLU3 [label="ReLU Activation"]
	Conv4 [label="Conv2D: 32x32x256
kernel=3x3, padding=1"]
	ReLU4 [label="ReLU Activation"]
	Pool [label="Max Pooling: 16x16x256
window=2x2"]
	Flatten [label="Flatten: 65536"]
	Dense1 [label="Dense: 512"]
	ReLU5 [label="ReLU Activation"]
	Dropout [label="Dropout: 0.5"]
	Dense2 [label="Dense: 10"]
	Output [label="Output Layer: 10"]
	Input -> Conv1
	Conv1 -> ReLU1
	ReLU1 -> Conv2
	Conv2 -> ReLU2
	ReLU2 -> Conv3
	Conv3 -> ReLU3
	ReLU3 -> Conv4
	Conv4 -> ReLU4
	ReLU4 -> Pool
	Pool -> Flatten
	Flatten -> Dense1
	Dense1 -> ReLU5
	ReLU5 -> Dropout
	Dropout -> Dense2
	Dense2 -> Output
}
