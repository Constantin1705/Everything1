{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.17.2+cu121)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bance\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bance\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bance\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bance\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/938], Loss: 0.26583331823349\n",
      "Epoch [1/5], Step [200/938], Loss: 0.1979304999113083\n",
      "Epoch [1/5], Step [300/938], Loss: 0.2215731292963028\n",
      "Epoch [1/5], Step [400/938], Loss: 0.027187854051589966\n",
      "Epoch [1/5], Step [500/938], Loss: 0.10458440333604813\n",
      "Epoch [1/5], Step [600/938], Loss: 0.04334958642721176\n",
      "Epoch [1/5], Step [700/938], Loss: 0.06950472295284271\n",
      "Epoch [1/5], Step [800/938], Loss: 0.18899568915367126\n",
      "Epoch [1/5], Step [900/938], Loss: 0.024309495463967323\n",
      "Epoch [2/5], Step [100/938], Loss: 0.030632618814706802\n",
      "Epoch [2/5], Step [200/938], Loss: 0.04329485073685646\n",
      "Epoch [2/5], Step [300/938], Loss: 0.02735838294029236\n",
      "Epoch [2/5], Step [400/938], Loss: 0.04314698278903961\n",
      "Epoch [2/5], Step [500/938], Loss: 0.05688460171222687\n",
      "Epoch [2/5], Step [600/938], Loss: 0.06867429614067078\n",
      "Epoch [2/5], Step [700/938], Loss: 0.01020274218171835\n",
      "Epoch [2/5], Step [800/938], Loss: 0.02424243651330471\n",
      "Epoch [2/5], Step [900/938], Loss: 0.07050655037164688\n",
      "Epoch [3/5], Step [100/938], Loss: 0.021113857626914978\n",
      "Epoch [3/5], Step [200/938], Loss: 0.030039122328162193\n",
      "Epoch [3/5], Step [300/938], Loss: 0.025133773684501648\n",
      "Epoch [3/5], Step [400/938], Loss: 0.01116194762289524\n",
      "Epoch [3/5], Step [500/938], Loss: 0.02067728526890278\n",
      "Epoch [3/5], Step [600/938], Loss: 0.0053115603514015675\n",
      "Epoch [3/5], Step [700/938], Loss: 0.010427653789520264\n",
      "Epoch [3/5], Step [800/938], Loss: 0.05823400989174843\n",
      "Epoch [3/5], Step [900/938], Loss: 0.032437004148960114\n",
      "Epoch [4/5], Step [100/938], Loss: 0.01799946278333664\n",
      "Epoch [4/5], Step [200/938], Loss: 0.026773903518915176\n",
      "Epoch [4/5], Step [300/938], Loss: 0.00956813246011734\n",
      "Epoch [4/5], Step [400/938], Loss: 0.0024674241431057453\n",
      "Epoch [4/5], Step [500/938], Loss: 0.08610573410987854\n",
      "Epoch [4/5], Step [600/938], Loss: 0.03132549673318863\n",
      "Epoch [4/5], Step [700/938], Loss: 0.002970046829432249\n",
      "Epoch [4/5], Step [800/938], Loss: 0.009664390236139297\n",
      "Epoch [4/5], Step [900/938], Loss: 0.04608561843633652\n",
      "Epoch [5/5], Step [100/938], Loss: 0.04794309288263321\n",
      "Epoch [5/5], Step [200/938], Loss: 0.020822905004024506\n",
      "Epoch [5/5], Step [300/938], Loss: 0.007386163808405399\n",
      "Epoch [5/5], Step [400/938], Loss: 0.03722532466053963\n",
      "Epoch [5/5], Step [500/938], Loss: 0.006843044422566891\n",
      "Epoch [5/5], Step [600/938], Loss: 0.012816251255571842\n",
      "Epoch [5/5], Step [700/938], Loss: 0.006919858045876026\n",
      "Epoch [5/5], Step [800/938], Loss: 0.0032320579048246145\n",
      "Epoch [5/5], Step [900/938], Loss: 0.0011155526153743267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bance\\AppData\\Local\\Temp\\ipykernel_30816\\2382780966.py:99: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  data_grad = single_image.grad.data\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 120\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpsilon: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepsilon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mAdversarial Test Accuracy = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect_adv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_loader\u001b[38;5;241m.\u001b[39mdataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_acc_adv\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    119\u001b[0m train(model, device, train_loader, criterion, optimizer)\n\u001b[1;32m--> 120\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Test with epsilon = 0.1\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 99\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(model, device, test_loader, epsilon)\u001b[0m\n\u001b[0;32m     96\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# IMPORTANT: Access the gradient after backward and before zero_grad\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m data_grad \u001b[38;5;241m=\u001b[39m \u001b[43msingle_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Call FGSM Attack\u001b[39;00m\n\u001b[0;32m    102\u001b[0m perturbed_data \u001b[38;5;241m=\u001b[39m fgsm_attack(single_image, epsilon, data_grad)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'data'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7*7*32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "def train(model, device, train_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item()}')\n",
    "\n",
    "# FGSM Attack\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image\n",
    "\n",
    "def test(model, device, test_loader, epsilon):\n",
    "    correct_normal = 0  # For normal accuracy\n",
    "    correct_adv = 0     # For adversarial accuracy\n",
    "    adv_examples = []\n",
    "\n",
    "    model.eval()\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        images.requires_grad = True\n",
    "\n",
    "        # Forward pass the original images\n",
    "        outputs = model(images)\n",
    "        _, init_pred = outputs.max(1, keepdim=True)  # Get the index of the max log-probability\n",
    "\n",
    "        correct_normal += (init_pred == labels.view_as(init_pred)).sum().item()\n",
    "\n",
    "        # Loop over all examples in batch\n",
    "        for idx in range(images.size(0)):\n",
    "            single_image = images[idx].unsqueeze(0)  # add batch dimension\n",
    "            single_label = labels[idx].unsqueeze(0)  # add batch dimension\n",
    "\n",
    "            # Forward pass the single image\n",
    "            output = model(single_image)\n",
    "            loss = criterion(output, single_label)  # Correct target shape\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # IMPORTANT: Access the gradient after backward and before zero_grad\n",
    "            data_grad = single_image.grad.data\n",
    "\n",
    "            # Call FGSM Attack\n",
    "            perturbed_data = fgsm_attack(single_image, epsilon, data_grad)\n",
    "            output = model(perturbed_data)\n",
    "            final_pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "            if final_pred.item() == single_label.item():\n",
    "                correct_adv += 1\n",
    "            else:\n",
    "                if len(adv_examples) < 5:  # Save some examples to view later\n",
    "                    adv_examples.append((init_pred[idx].item(), final_pred.item(), single_image.squeeze().cpu().numpy()))\n",
    "\n",
    "    # Calculate final accuracy for normal and adversarial examples\n",
    "    final_acc_normal = correct_normal / float(len(test_loader.dataset))\n",
    "    final_acc_adv = correct_adv / float(len(test_loader.dataset))\n",
    "    print(f'Epsilon: {epsilon}\\tNormal Test Accuracy = {correct_normal} / {len(test_loader.dataset)} = {final_acc_normal * 100}%')\n",
    "    print(f'Epsilon: {epsilon}\\tAdversarial Test Accuracy = {correct_adv} / {len(test_loader.dataset)} = {final_acc_adv * 100}%')\n",
    "\n",
    "\n",
    "train(model, device, train_loader, criterion, optimizer)\n",
    "test(model, device, test_loader, epsilon=0.1)  # Test with epsilon = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
